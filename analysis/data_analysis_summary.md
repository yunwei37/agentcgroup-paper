# AgentCgroup 实验数据分析总结

**生成时间**: 2026-02-06
**分析脚本**:
- `analyze_rq_validation.py` - RQ1-RQ4 基础验证
- `analyze_tool_time_ratio.py` - 工具时间占比分析
- `analyze_haiku_vs_qwen.py` - 模型对比分析
- `analyze_extended_insights.py` - 扩展洞察分析（磁盘、启动开销、瞬态突发、CPU-Memory相关性、重试循环、本地推理等）

## 数据集概览

| 数据集 | 模型 | 任务数 | 成功率 | 总执行时间 | 图表目录 |
|--------|------|--------|--------|------------|----------|
| batch_swebench_18tasks | Haiku | 18 | 94.4% (17/18) | 119.9 min | `haiku_figures/` |
| all_images_local | Qwen | 102 | 52.9% (54/102) | 1069.7 min | `qwen3_figures/` |

---

## RQ1: 时间尺度不匹配 (Timescale Mismatch)

**论文主张**: 用户空间控制器反应时间 10-100ms，但 AI agent 的资源使用在毫秒级发生剧烈变化。

### 实验数据支持

| 指标 | batch_swebench_18tasks | all_images_local |
|------|------------------------|------------------|
| 最大 CPU 变化 (1秒内) | **41.6%** | **53.0%** |
| 最大内存变化 (1秒内) | **2983.5 MB** | **1844.9 MB** |
| 突发事件数 (CPU>20% 或 Mem>50MB) | 244 次 | 726 次 |
| 突发事件占比 | 4.1% | 1.6% |

### 关键发现

1. **内存突发极其剧烈**: 在单个采样间隔（~1秒）内，内存变化可达 **3GB**
2. **CPU 变化频繁**: 最大 CPU 变化超过 50%，远超用户空间控制器的调节能力
3. **采样间隔限制**: 当前采样间隔为 1 秒，实际变化可能更快（毫秒级）

**结论**: ✅ **数据强力支持论文主张**

---

## RQ2: 域不匹配 (Domain Mismatch)

**论文主张**: 传统 cgroup 在容器级别设置静态资源限制，但不同任务/工具有不同的资源需求。

### 实验数据支持

| 指标 | batch_swebench_18tasks | all_images_local |
|------|------------------------|------------------|
| 峰值内存范围 | 279 - 4060 MB | 197 - 2041 MB |
| 峰值内存变异系数 (CV) | **147.3%** | **65.7%** |
| 峰值 CPU 范围 | 104 - 129% | 65 - 118% |

### 按任务类别资源消耗差异 (batch_swebench_18tasks)

| 类别 | 平均 CPU | 平均内存 |
|------|----------|----------|
| CLI_Tools | ~30% | ~250 MB |
| DevOps_Build | ~35% | ~400 MB |
| ML_Scientific | ~28% | ~600 MB |
| Medical_Bio | ~25% | ~350 MB |
| SQL_Data | ~30% | ~300 MB |
| Web_Network | ~25% | ~280 MB |

**关键发现**:
- 内存需求变异系数高达 **147%**，表明不同任务的资源需求差异巨大
- 不能用一个静态限制适配所有任务

**结论**: ✅ **数据支持论文主张**

---

## RQ3: 工具调用模式分析

### all_images_local 工具时间分布

| 指标 | 值 |
|------|-----|
| 工具执行时间占比 | **28.2%** |
| LLM 思考时间占比 | **71.8%** |
| 平均工具时间比例 | 25.2% |
| 工具时间比例范围 | 0.1% - 73.3% |

### Bash 命令分类

| 类别 | 时间占比 | 调用次数 |
|------|----------|----------|
| Test Execution | **44.1%** | 810 |
| Python Snippet | 26.7% | 599 |
| Package Install | 10.9% | 189 |
| File Exploration | 6.2% | 366 |
| Python Run | 4.7% | 266 |
| Text Processing | 4.4% | 349 |
| Git Operations | 2.1% | 289 |

**关键发现**:
- 测试执行占 Bash 时间的 **44%**，是最耗资源的操作
- 工具调用模式高度动态，需要细粒度控制

---

## RQ4: 过度供给分析 (Overprovisioning)

**论文主张**: 静态资源限制需要设置为峰值，导致大量资源浪费。

### 过度供给因子

| 数据集 | 内存过度供给 | CPU 过度供给 |
|--------|--------------|--------------|
| batch_swebench_18tasks | **2.43x** | **4.10x** |
| all_images_local | 1.59x | **13.60x** |

### 静态限制下的资源利用率

| 数据集 | 内存利用率 | CPU 利用率 |
|--------|------------|------------|
| batch_swebench_18tasks | 41% | **24%** |
| all_images_local | 63% | **7%** |

**关键发现**:
- 如果使用静态 CPU 限制（设为峰值），实际利用率仅 **7-24%**
- 这意味着 **76-93% 的 CPU 配额被浪费**
- 细粒度动态控制可以显著提升资源效率

**结论**: ✅ **数据强力支持论文主张**

---

## RQ5: 不同模型的资源使用差异 (Haiku vs Qwen)

**论文主张**: 不同的 AI agent（模型）在相同任务上表现出不同的资源使用模式。

### 实验数据支持

| 指标 | Haiku | Qwen | 差异 |
|------|-------|------|------|
| 成功率 | **94.4%** (17/18) | 44.4% (8/18) | 2.1x |
| 平均执行时间 | 400s | 607s | Qwen 1.52x 慢 |
| 平均峰值内存 | 611 MB | 463 MB | Haiku 1.32x |
| 平均 CPU 利用率 | **30.6%** | 7.9% | Haiku **3.9x** |

### 按类别成功率

| 类别 | Haiku | Qwen |
|------|-------|------|
| CLI_Tools | 3/3 (100%) | 1/3 (33%) |
| DevOps_Build | 3/3 (100%) | 2/3 (67%) |
| ML_Scientific | 2/3 (67%) | 0/3 (0%) |
| Medical_Bio | 3/3 (100%) | 2/3 (67%) |
| SQL_Data | 3/3 (100%) | 0/3 (0%) |
| Web_Network | 3/3 (100%) | 3/3 (100%) |

### 关键发现

1. **成功率差异显著**: Haiku 在 Qwen 成功的所有任务上都成功，额外成功 9 个任务
2. **资源使用模式差异**: CPU 利用率相差 **3.9 倍**，说明不同模型的计算模式完全不同
3. **执行效率差异**: Haiku 更高效（时间短、成功率高），但资源消耗也更高
4. **对论文的启示**: 即使相同任务，不同 AI agent 也需要不同的资源配置策略

**结论**: ✅ **进一步支持域不匹配论点** - 静态资源限制无法适应不同 AI agent 的多样化需求

详细报告见: [`haiku_vs_qwen_report.md`](haiku_vs_qwen_report.md)

图表位置: `comparison_figures/`

---

## 总结：数据与论文主张的一致性

| 论文核心主张 | 数据支持程度 | 关键证据 |
|--------------|--------------|----------|
| 时间尺度不匹配 | ✅ **强支持** | 1秒内内存变化达 3GB，CPU 变化 >50% |
| 域不匹配 | ✅ **支持** | 任务间资源需求 CV 高达 147% |
| 静态控制导致浪费 | ✅ **强支持** | CPU 利用率仅 7-24%，浪费 76-93% |
| 需要细粒度控制 | ✅ **支持** | 测试执行占 44% 时间，工具模式动态变化 |
| 不同 Agent 需求差异 | ✅ **支持** | Haiku vs Qwen CPU 利用率差异 3.9x |

---

## 建议的论文改进

1. **增加更细粒度的采样**: 当前 1 秒采样间隔可能低估实际变化速度，建议增加 100ms 或更细的采样
2. **工具级资源追踪**: 将资源使用与具体工具调用对齐，展示不同工具的资源消耗差异
3. **对照实验**: 对比有/无 AgentCgroup 的资源利用率改善
4. **多租户场景**: 展示并发 AI agent 时的资源竞争和隔离效果
5. **跨模型对比**: 利用 Haiku vs Qwen 数据展示不同 AI agent 的资源异构性

# 3 Characterization

我们对生产级 AI coding agent 的资源使用模式进行了首次系统性测量研究，旨在回答以下研究问题：**RQ1**: Agent 的执行模型是什么？**RQ2**: Agent 工作负载的资源使用有何特征？并且讨论 AI coding agent 的资源使用模式和传统的容器化工作负载之间的根本差异，以及这些差异对现有资源管理工具的适用性和效率的影响。

## 3.1 Experimental Setup

**实验平台。** 所有实验在一台配备 Intel Core Ultra 9 285K 处理器（24 核，最高 5.8 GHz）、128 GB DDR5 内存的机器上运行，操作系统为 Ubuntu 24.04.3 LTS，内核版本 Linux 6.15.11（已启用 cgroup v2）。每个任务在独立的 Podman 容器中执行，容器镜像来自 SWE-rebench 官方 Docker 镜像（单个镜像大小 2.9–17.3 GB）。characterization 实验期间不对容器施加任何资源限制，以确保测量反映无约束条件下的真实资源需求。

**数据集。** 我们采用两级数据集策略。首先，从 SWE-rebench 数据集中收集 111 个任务（GLM 本地模型）和 33 个任务（Haiku 云端模型），用于大规模统计分析。此外，我们精选 18 个代表性任务，覆盖六个类别（CLI_Tools、DevOps_Build、ML_Scientific、Medical_Bio、SQL_Data、Web_Network）和三个难度级别（Easy、Medium、Hard），用于类别级分析。这些任务涵盖了 AI coding agent 的典型使用场景，包括命令行工具修复、构建系统配置、机器学习代码调试、生物医学数据处理、数据库查询优化和 Web 服务修复。

**Agent 实现。** 所有任务均使用同一 agent 框架——Claude Code 执行，配合两个不同的底层模型：（1）Haiku（云端 API），LLM 推理在 Anthropic 云端执行；（2）GLM 4.7 flash（本地 GPU），LLM 推理通过 GPU 在本地设备上执行。Agent 框架本身（工具调用逻辑、沙箱环境、Node.js 运行时）完全相同，差异仅在于底层模型及其推理位置。选择这两个模型是为了观察不同模型（及其推理位置：远程 API vs 本地 GPU）对容器内资源使用的影响。

**数据收集。** 对于每个任务执行，我们以 1 秒间隔采样每个容器的 CPU 利用率和内存使用量，并记录每个工具调用的类型、开始时间和结束时间。所有任务在相同的沙箱环境中执行，以确保测量的可比性。

## 3.2 RQ1: Agent Execution Model

Agent 的执行过程与传统容器化工作负载存在根本差异。与 serverless/FaaS 处理短暂无状态请求（100ms–2s）不同，每个 agent 任务平均运行约 10 分钟（GLM 平均 10.8 分钟，Haiku 平均 5.8 分钟，中位数 8.1 分钟；见 Fig-exec (a)），并执行有状态的多轮推理和工具调用循环。此外，容器启动存在不可忽视的固定开销，平均需要 26.5 秒（中位数 23.0 秒），最长可达 97 秒。

**约 6 成时间用于推理、4 成用于工具执行，但任务间差异巨大（0%–86%）。** Agent 执行由 LLM 推理和工具调用两个阶段交替组成。如 Fig-exec (b) 所示，在全部 144 个任务（Haiku 33 + GLM 111）中，以 `active_time`（trace 首条到末条记录的时间跨度，排除容器启动开销）为分母，工具执行时间的中位数占比约 35%（Haiku 34.7%、GLM 36.5%），均值为 Haiku 42.5%、GLM 36.4%。两个模型的中位数接近，表明约 6 成时间用于 LLM 思考、4 成时间用于工具执行的阶段划分是 agent 工作负载的共性特征。然而，这一比例在不同任务间差异巨大，范围从 0% 到 86%（中位数 ~36%），如 Fig-tool-time (a) 所示。

**端到端延迟中，LLM 思考仅占 26–44%，其余为基础设施开销。** 以 `claude_time`（容器完整生命周期）为分母分析端到端任务延迟的构成：容器启动开销占 31–48%（Haiku 47.7%、GLM 31.0%），工具执行占约 26%（两模型一致：Haiku 25.9%、GLM 25.5%），LLM 实际思考仅占 26%（Haiku）到 44%（GLM）。换言之，基础设施开销（容器启动 + 工具执行）占据了 57–74% 的端到端延迟。这一发现表明，OS 级的容器和资源管理直接影响超过一半的 agent 任务延迟——优化工具执行期间的资源控制不仅关乎资源效率，更直接关乎用户感知的任务完成时间。

![Fig-exec: 任务执行时间分布 (a) 与执行阶段划分 (b)](../../analysis/comparison_figures/exec_overview.pdf)

**Bash 和 Task 占据工具执行时间的 90% 以上，但不同模型的工具策略截然不同。** 如 Fig-tool-type 所示，以 Haiku agent（33 个任务）为例分析工具调用结构（Fig-tool-type (a)）。Task（子 agent 调用）和 Bash 分别占工具总执行时间的 47.8%（n=17）和 43.2%（n=410），WebSearch/WebFetch 合计约 5%，其余工具（Read、Grep、Edit 等）合计不足 5%。相比之下，GLM agent 几乎完全依赖 Bash 调用（占工具时间的 99.5%，n=3304），不使用 Task 子 agent 和 Web 搜索工具。进一步分析 Bash 命令的语义类别（Fig-tool-type (b)），在 Haiku 中测试执行（pytest、unittest 等）占 Bash 总时间的 72.9%，包安装占 10.8%；GLM 的分布更分散——测试执行 43.7%、Python 片段 26.9%、包安装 10.1%。不同类型的工具调用具有截然不同的资源消耗特征：测试执行通常是 CPU 和内存密集型操作，而文件探索和 Git 操作则相对轻量。

![Fig-tool-type: 工具执行时间分布 (a) 与 Bash 命令语义类别占比 (b)，GLM agent](../../analysis/comparison_figures/tool_bash_breakdown.pdf)

**不同工具类型的执行时间跨越三个数量级。** Haiku 的 Task 子 agent 平均执行时间高达 100.47 秒（n=17），Bash 命令平均 3.76 秒（n=410）；GLM 的 Bash 命令平均 5.93 秒（n=3304）。相比之下，Read（Haiku avg 0.34s / GLM avg 0.08s）和 Edit（Haiku avg 0.05s / GLM avg 0.04s）操作的执行时间快三个数量级。这种差异表明，不同工具类型需要不同的资源配置策略。两个模型的工具策略差异也具有资源管理启示：Haiku 模型通过 Task 子 agent 和 Web 搜索将部分工作分发到外部服务，而 GLM 模型将所有计算集中在本地 Bash 执行，导致更高的本地资源消耗（Bash 总时间 19598s vs Haiku 1543s）。

**工具调用遵循"理解-修改-验证"的时间模式。** 如 Fig-tool-time (b) 所示，将执行过程划分为 10 个等长阶段后分析工具调用分布，我们发现 Read 操作集中在执行早期（前 30%），对应代码理解阶段；Bash 调用在中后期（40-80%）最为密集，对应测试和验证阶段；Edit 操作分布相对均匀，贯穿整个执行过程。这种阶段性特征与软件工程的"理解-修改-验证"工作流吻合，为相位感知资源控制提供了依据。

![Fig-tool-time: 工具时间占比分布 (a) 与工具调用随执行进度的分布 (b)，全部 144 个任务](../../analysis/comparison_figures/tool_time_pattern.pdf)

## 3.3 RQ2: Resource Usage Characteristics

在 RQ1 描述的执行模型之上，本节进一步分析 agent 工作负载的资源使用特征。我们首先给出资源占用的宏观画像，然后从时间动态性、非确定性和异构性三个维度分析其不可预测性。

**内存而非 CPU 是多租户并发密度的决定性瓶颈。** Agent 的平均 CPU 利用率极低（Haiku 13.2%、GLM 7.6%，单核基准），在 24 核实验平台上 CPU 远未饱和。内存才是并发密度的决定性约束：峰值内存可达 2–4GB，128GB 内存按峰值分配仅能支撑 32–64 个实例，此时 CPU 利用率仍不超过总容量的 36%。这种 CPU 大量闲置而内存成为瓶颈的失衡，意味着动态内存管理是提升并发密度的关键——在短暂的内存突发时弹性扩展，在空闲期回收资源以容纳更多并发实例。

**磁盘存储需求远超传统容器化应用。** 如 Fig-resource (a) 所示，在去重后的 114 个独立镜像中，Docker 镜像大小范围从 2.9GB 到 17.3GB，平均 4.1GB，中位数 3.5GB，且高度集中在 3–4GB 区间，仅 GLM 111 个任务的镜像总量即达 456GB，对多租户部署形成显著的存储压力。

**资源消耗呈现 ~185MB 框架基线与工具突发叠加的两层结构。** 如 Fig-resource (b) 所示，Agent 框架本身（如 Claude Code 基于 Node.js 运行时）维持一个不可压缩的内存基线：跨所有 144 个任务，执行前期（前 10% 采样点）的平均内存为 Haiku 183MB、GLM 188MB，中位数约 185MB。即使在 LLM 推理阶段（无工具调用），内存也始终维持在这一基线水平。而资源的剧烈波动几乎完全来自工具调用产生的子进程：测试执行、依赖安装等操作将内存瞬间拉高至 500MB–2GB，随后回落到基线。将所有任务的内存使用归一化到执行进度后聚合分析（Fig-resource (b)），执行前半段（0-50%）内存保持相对稳定的基线（约 185-200MB），而后半段内存呈现上升趋势并伴随更大的方差，与 Bash 密集阶段的资源消耗一致。这意味着在多租户场景下，64 个并发实例仅框架基线就需要约 12GB 内存，而工具突发的叠加才是真正的资源管理挑战。资源控制策略需要区分这两个层面——为框架基线提供稳定保障，同时对工具突发进行弹性调度。

**资源消耗由工具语义而非工具类型决定，同为 Bash 调用可差异 13.7 倍。** 相同类型的工具调用（如 Bash）在不同任务上产生截然不同的资源消耗。例如，在 18 个代表性任务中，Medical_Bio 类别的 Bash 调用平均消耗 4GB 峰值内存，而 Web_Network 类别仅需 291MB，差异达到 13.7 倍。这表明资源需求不是由工具类型决定的，而是由工具执行的具体语义决定的——测试执行、数据加载、模型推理等操作即使都通过 Bash 工具调用，其资源特征也完全不同。这一发现对资源控制策略有重要启示：仅基于工具类型的资源分配是不够的，需要更细粒度的语义感知控制。进一步量化不同 Bash 命令类别的资源突发幅度：测试执行（pytest 等）的 P95 内存 spike 高达 518MB（Haiku）/ 234MB（GLM），平均 CPU spike +3.2%；包安装的 P95 内存 spike 约 233MB；而文件探索和 Git 操作的平均内存 spike 仅为 4.5MB 和 13.5MB。同为 Bash 调用，不同语义类别的内存突发幅度相差两个数量级（518MB vs 4.5MB），为基于命令语义的差异化资源配额提供了直接依据。

![Fig-resource: Docker 镜像大小分布 (a) 与聚合内存轨迹 (b)，全部 144 个任务](../../analysis/comparison_figures/resource_profile.pdf)

这种资源特征的不可预测性源于三个维度：时间动态性、非确定性和异构性。

### 时间动态性

Agent 工作负载的资源使用呈现剧烈的时间波动特征。可以观察到，内存使用在单个采样间隔（1 秒）内变化高达 2.9GB，CPU 利用率出现剧烈波动，峰值超过 100%（多核利用）。资源使用呈现明显的"突发"模式，而非平稳变化。

![Fig-timeseries-haiku: 资源使用时序 — Haiku agent 执行 pre-commit/pre-commit#2524](../../analysis/haiku_figures/rq1_resource_timeseries.pdf)

![Fig-timeseries-glm: 资源使用时序 — GLM agent 执行 sigmavirus24/github3.py#673](../../analysis/qwen3_figures/rq1_resource_timeseries.pdf)

Fig-timeseries-haiku 和 Fig-timeseries-glm 展示了两个具体任务的资源使用时序作为示例：上方为使用 Haiku agent 执行的 pre-commit/pre-commit#2524 任务，下方为使用 GLM agent 执行的 sigmavirus24/github3.py#673 任务。每张图包含两个子图：上方为 CPU 利用率（蓝色），下方为内存使用（绿色），红色阴影区间标注了工具调用（Bash、Read、Edit 等）的执行时段。可以清晰看到资源突发与工具调用高度对齐——CPU 和内存的尖峰几乎都发生在工具执行期间（如运行测试、安装依赖），而工具调用之间的 LLM 推理阶段资源使用相对平稳。这两个示例也体现了不同模型的典型资源差异：Haiku 任务工具调用较为集中，每次执行伴随明显的 CPU 多核突增（峰值超过 175%）；GLM 任务工具调用更加密集频繁，但 CPU 长期维持低水平（~10%），资源波动主要体现在内存维度。尽管具体的资源曲线因任务而异，但这种由工具调用驱动的"突发-静默"交替模式在两个数据集的所有任务中普遍存在。

**98.5% 的内存突发发生在工具调用期间，资源波动几乎完全由工具执行驱动。** 为量化这一现象，我们将每个资源采样点标注为"工具调用中"或"LLM 推理中"，统计超过 300MB 的内存突发事件的归属。在 Haiku 数据集中，工具调用仅占总采样时间的 50.6%，却包含了 98.5% 的内存突发；GLM 数据集中，工具调用占 35.9% 的时间，包含 67.3% 的内存突发。两个数据集的内存突发集中度均为 1.9 倍——即工具调用期间产生内存突发的概率是其时间占比的近 2 倍。CPU 突发的归因则更加分散：Haiku 中 55.3% 的 CPU 突发发生在工具调用期间，GLM 中仅为 30.2%（GLM 的 CPU 突发主要来自本地 GPU 推理的调度开销）。这种不对称性——内存突发高度集中在工具调用中，而 CPU 突发分布更均匀——意味着内存资源应以工具调用为粒度进行弹性调度，而 CPU 资源需要更广泛的上下文感知。

如 Fig-change-rate 所示，我们观察到最大内存变化率达到 3GB/秒，最大 CPU 变化率超过 50%/秒。显著变化事件占所有采样点的 1.7%–3.8%。

![Fig-change-rate: 资源变化率分布（CPU 与内存），Haiku 数据集](../../analysis/haiku_figures/rq1_change_rate_distribution.pdf)

**资源突发仅持续 1-2 秒，峰均比高达 15.4 倍，静态限制无论如何设置都不合理。** 资源突发呈现极端的瞬态性（如 Fig-timeseries-haiku 和 Fig-timeseries-glm 中的尖峰所示）。在 18 个代表性任务中，以 Medical_Bio_Hard 任务为例，峰值内存达到 4060MB，而平均内存仅为 264MB，过度供给因子高达 15.4 倍。关键在于，这个 4GB 的峰值仅持续约 1-2 秒，随后立即回落到 230MB 的基线水平。这种"尖峰"模式意味着：如果按峰值设置静态限制，98% 的时间资源都被浪费；如果按平均值设置，则会在突发时触发 OOM。传统的反应式资源调整无法应对如此短暂的突发。

**CPU 与内存的相关性因任务而异（-0.84 到 +0.50），无法假设同向变化。** 如 Fig-timeseries-haiku 和 Fig-timeseries-glm 所示，CPU 和内存使用之间的相关性呈现显著的任务依赖性。跨所有任务的平均相关系数为 -0.39（范围从 -0.84 到 +0.50），表明大多数任务中 CPU 高峰和内存高峰并不同步出现。部分任务呈现正相关（工具执行阶段同时拉高 CPU 和内存），而另一些任务呈现负相关（CPU 密集阶段的内存需求较低，反之亦然）。这种任务依赖的耦合模式比简单的正/负相关更难应对：资源控制策略无法假设 CPU 和内存需求总是同向变化，必须对两种资源维度进行独立监控和协调管理。

内存峰值集中在执行后半段（均值/中位数约 65% 进度处，见 Fig-resource (b)），但分布范围覆盖整个执行周期，这种不可预测性进一步增加了静态资源分配的难度。

### 非确定性

与传统容器化工作负载不同，agent 工作负载表现出高度的非确定性。即使对完全相同的任务执行多次，资源使用模式和执行结果也会显著不同。我们对同一任务（DevOps_Build_Hard）执行了三次，观察到：执行时间分别为 402 秒、222 秒和 259 秒，差异达到 1.8 倍。更重要的是，三次执行产生了完全不同的解决方案——不同的代码修改、不同的文件变更数量、甚至不同的实现策略。这种非确定性源于 LLM 推理的随机性和 agent 决策路径的多样性，使得基于历史数据预测资源需求变得极其困难。

**85%–97% 的任务包含重试循环，消耗 7%–20% 的执行时间并导致内存逐次积累。** 重试是 agent 工作负载的固有行为：Haiku 数据集中 85%（28/33）的任务包含重试组（连续 3 次以上的 Bash 调用），GLM 数据集中这一比例高达 97%（108/111）。GLM 平均每个任务 3.9 个重试组，最大连续重试达 56 次，重试时间平均占总执行时间的 20.5%（Haiku 为 7.4%）。这种"执行测试—观察失败—修改代码—再次测试"的迭代模式是 agent 的行为签名。更重要的是，每次重试循环保留之前的内存上下文而不清理，导致内存逐渐积累——最极端的案例中，重试导致 502MB 的内存累积不释放。这种行为模式在传统容器化工作负载中罕见，但在 agent 工作负载中普遍存在，且其资源影响无法提前预测。

**LLM 生成的 token 数量无法预测资源消耗。** 分析 Haiku 数据集中每个任务的 output token 总量与其峰值内存的相关性，相关系数仅为 r=−0.14（GLM r=+0.02），基本不存在线性相关。对话轮数与执行时间有中等相关（Haiku r=+0.57，GLM r=+0.82），但与峰值内存几乎无关（Haiku r=+0.02，GLM r=+0.11）。这意味着即使可以预测 agent 会产生多少 token 或多少轮对话，也无法据此预测内存需求——资源消耗主要取决于工具调用的语义，而非 LLM 推理本身的规模。

### 异构性

不同任务和不同模型之间的资源需求存在显著差异。在 18 个代表性任务中，峰值内存需求范围从 197MB 到 4GB，变异系数（CV）达到 147%。ML_Scientific 和 Medical_Bio 类别的任务表现出显著高于 CLI_Tools 或 Web_Network 任务的内存需求，但所有任务都在同一个容器中运行。

Haiku 和 GLM 在相同任务上表现出显著的 CPU 利用率差异（Haiku 平均 13.2%，GLM 平均 7.6%，差异 1.7 倍）。平均执行时间也存在显著差异（Haiku 352 秒，GLM 664 秒）。这一结果表明，资源需求不仅取决于任务本身，还取决于底层模型的选择。

**仅更换底层模型即产生截然不同的资源画像。** 这种 CPU 利用率差异反映的本质问题是：即使 agent 框架完全相同（均为 Claude Code），仅更换底层模型就会产生截然不同的资源画像。Haiku 通过云端 API 推理，API 调用、响应解析和上下文管理消耗较多本地 CPU；GLM 的推理在本地 GPU 上执行，容器内 CPU 负载几乎仅来自工具调用——GLM 容器内仅有 0.5% 的采样点 CPU 利用率超过 50%，而 Haiku 达到 8.2%。即使执行相同任务，两个模型的 CPU 分布、执行时长和内存轨迹也显著不同。这意味着资源管理策略无法基于"agent 工作负载"这一单一类别做静态假设，而必须适配不同模型带来的资源特征差异。
# 4 Gap Analysis

前两节的测量揭示了 agent 工作负载的独特资源特征。本节将这些特征置于已知云工作负载的坐标系中进行定量对比，并系统性地分析现有资源管理方案——从内核 cgroup 接口到集群级自动扩缩——为何无法有效管理 agent 工作负载。

## 4.1 与已知云工作负载类型的定量对比

为理解 agent 工作负载的独特性，我们将 RQ1 和 RQ2 的测量结果与三类典型云工作负载进行对比。

| 维度 | Serverless/FaaS | 微服务 | 批处理/HPC | **AI Coding Agent** |
|------|----------------|--------|-----------|---------------------|
| 执行时长 | 100ms–2s \cite{shahrad2020serverless} | 长驻 | 分钟–小时 | **5–11 分钟** |
| 状态性 | 无状态 | 外部状态 | 有状态 | **进程内有状态** |
| 内存 peak/avg | ~1.5× | 2–3× \cite{cortez2017resource} | ~1× | **15.4×** |
| 确定性 | 确定性 | 基本确定 | 确定性 | **同任务 1.8× 方差** |
| 资源模式 | 平坦 | 稳态+日周期 | 稳定上升 | **突发-静默交替** |
| 终止代价 | 重试即可 | 可漂移 | 丢失进度 | **丢失全部 LLM 上下文** |

**内存峰均比是最显著的差异指标。** Shahrad 等人对 Azure Functions 的大规模研究表明，serverless 函数的典型内存分配为 256MB，运行时内存波动极小 \cite{shahrad2020serverless}。Cortez 等人对 Azure VM 工作负载的分析显示，大多数 VM 的内存利用率在其生命周期内保持相对稳定，peak/avg 通常在 2–3× 范围内 \cite{cortez2017resource}。Google Autopilot 的经验表明，对于大多数 Borg 作业，推荐的资源上限在实际峰值的 2× 以内即可覆盖 \cite{rzadca2020autopilot}。相比之下，agent 工作负载的内存 peak/avg 可达 15.4×（Medical\_Bio\_Hard 任务：峰值 4060MB / 均值 264MB），远超上述工作负载类型。这一极端比值源于 agent 独有的两层结构：框架基线（~185MB）在 LLM 推理期间保持稳定，而工具调用（特别是测试执行和依赖安装）产生持续仅 1–2 秒的内存尖峰。

**非确定性使历史预测失效。** 传统云工作负载的资源需求具有可预测性：Borg 的历史利用率数据可有效指导资源分配 \cite{verma2015borg, tirmazi2020borg}；Autopilot 利用历史 P95 指标进行自动推荐，对大多数作业有效 \cite{rzadca2020autopilot}。然而，agent 工作负载的资源消耗由 LLM 推理驱动，而 LLM 的输出具有内在随机性——同一任务执行三次产生完全不同的代码修改路径和资源曲线（执行时间变异系数达 1.8×）。此外，output token 数量与峰值内存之间几乎无相关性（r=−0.14），对话轮数与峰值内存同样无关（r=+0.02）。这意味着基于历史 metrics 的预测——包括移动平均、指数平滑或 percentile 方法——在 agent 工作负载上均不可靠。

**有状态 + 长时运行使终止成本极高。** Serverless 函数是无状态的，OOM kill 后可以简单地从头重试，典型重试延迟仅 100ms–2s \cite{shahrad2020serverless}。微服务可以通过 Pod 漂移和状态外置实现优雅降级。而 agent 的全部执行上下文——LLM 对话历史、中间代码修改、工具调用结果——都存储在进程内存中。一次 OOM kill 意味着丢失平均 10 分钟的有状态计算，且由于非确定性，重新执行不保证到达相同的解决路径。这种特性使得任何以"kill + restart"为降级手段的资源管理策略（包括 Kubernetes eviction 和 systemd-oomd）对 agent 工作负载代价过高。

## 4.2 现有资源管理方案的局限性

我们逐一分析从内核接口到集群编排的五类现有资源管理方案，阐明它们各自的设计假设以及为何这些假设不适用于 agent 工作负载。

**（1）cgroup v2 硬限制（`memory.max` / `--memory`）。** 这是 Docker 和 Kubernetes resource limits 的底层机制：当 cgroup 的内存使用达到 `memory.max` 时，内核在页面分配路径上同步触发 OOM kill \cite{cgroupv2}。对于 peak/avg 比值 2–3× 的传统工作负载，按峰值设置硬限制导致 50–67% 的过度供给，通常可以接受。但 agent 工作负载的 peak/avg 达到 15.4×：按峰值（4060MB）设置限制，98% 的时间内存使用低于 264MB，浪费率达 93%；按均值设置，1–2 秒的工具突发即触发 OOM kill，丢失全部 agent 状态。跨全部 144 个任务的聚合分析证实了这一两难——CPU 按峰值分配的过度供给因子高达 11.1×–13.9×。硬限制的根本问题在于它是一维、静态的阈值，无法表达 agent 工作负载的"低基线 + 高突发"两层结构。

**（2）cgroup v2 软限制（`memory.high`）。** `memory.high` 提供了比硬限制更灵活的机制：当内存使用超过该阈值时，内核触发 direct reclaim 和 throttling，而非 OOM kill \cite{cgroupv2}。这种设计对传统工作负载有效——reclaim 可以回收文件页缓存，throttling 减缓分配速率，通常不影响应用正确性。然而，agent 工作负载存在两个使 `memory.high` 失效的结构性问题。其一，reclaim 无法区分框架内存（Node.js 堆、V8 JIT 编译缓存，~185MB，不可回收）和工具子进程内存（pytest 运行、依赖安装，可限制但不应全部回收）。当 reclaim 作用于框架页面时，会导致 V8 GC 压力增大和 JIT 缓存失效，延长 LLM 响应解析时间，进而增加总执行时间。其二，`memory.high` 只能在容器粒度设置单一阈值，无法为不同工具调用设置差异化限制——`git status`（平均 spike 13.5MB）和 `pytest`（P95 spike 518MB）需要截然不同的内存配额，但它们共享同一个 cgroup。

**（3）PSI 驱动的用户空间方案（systemd-oomd、Meta oomd）。** 这类方案监控 cgroup 的 Pressure Stall Information（PSI）指标，当内存或 I/O 压力超过阈值时采取行动（通常是 kill 整个 cgroup 或触发 swap）\cite{systemd-oomd, psi}。其设计假设是：（a）压力信号出现后有足够的时间窗口做出决策，（b）kill 或迁移是可接受的降级手段。这两个假设对 agent 工作负载均不成立。假设（a）方面：agent 的内存突发持续仅 1–2 秒，变化率达 3GB/s（RQ2），PSI 信号从产生到用户空间 daemon 接收、决策、写入 cgroup 控制文件的完整循环需要数十毫秒，此时突发可能已经结束或已触发内核直接干预。假设（b）方面：systemd-oomd 的默认动作是 kill cgroup，对无状态服务可接受（自动重启），但对有状态 agent 意味着丢失全部上下文。更根本的是，PSI 是容器级别的聚合指标，无法归因到具体的工具调用——它只能告诉控制器"容器有压力"，而不是"正在运行的 pytest 进程导致了压力"。

**（4）集群级自动扩缩（Kubernetes VPA / Autopilot）。** Kubernetes Vertical Pod Autoscaler (VPA) 根据历史 metrics 的 percentile 统计推荐资源 request 和 limit，Autopilot 在 Google Borg 上实现了类似功能 \cite{k8s-vpa, rzadca2020autopilot}。这类方案的核心假设是资源需求在 Pod 的多次执行之间是可预测的，即"过去的 P95 是未来的合理上界"。Agent 工作负载违反了这一假设的两个前提。其一，**同一 agent 的资源需求因任务而异**：CLI\_Tools 类任务峰值内存 197MB，Medical\_Bio 类任务峰值 4060MB，差异 20×。VPA 的推荐值必然过高或过低。其二，**即使同一任务，重复执行的资源需求也不同**：非确定性使得历史 percentile 失去统计意义。此外，VPA 的调整粒度是 Pod 重启级别（当前稳定版）或分钟级别的 in-place resize（alpha 特性）\cite{k8s-inplace-resize}，而 agent 的工具突发发生在秒级——VPA 无法在一次执行内部动态调整资源。

**（5）Kubernetes QoS 等级与 CPU 带宽控制。** Kubernetes 将 Pod 分为 Guaranteed（request=limit）、Burstable（request<limit）和 BestEffort（无 request）三个 QoS 等级 \cite{k8s-qos}。Guaranteed 等价于静态分配，前述分析已表明浪费率达 91–93%。BestEffort 在节点压力下最先被驱逐，不适合有状态 agent。Burstable 允许 Pod 在 request 和 limit 之间弹性使用，是三者中最接近 agent 需求的选项，但它仍然是容器粒度的单一区间——无法区分 LLM 推理阶段（近零 CPU、低内存）和工具执行阶段（多核突发、高内存），也无法在同一容器内为不同工具调用设置差异化限额。CFS 带宽控制（`cpu.max`）同样面临困境：平坦的 CPU 配额在 API 等待期浪费、在测试执行期节流。Agent 的 CPU 需求呈现极端的双峰分布（GLM 容器仅 0.5% 的采样点超过 50% 利用率，但工具执行期 CPU 峰值超过 175%），单一的带宽配额无法同时适应两种模式。

## 4.3 Summary and Design Requirements

上述分析揭示了一条贯穿所有现有方案的共同局限：**控制粒度与 agent 工作负载的资源粒度不匹配**。现有方案在容器/Pod 粒度设置单一策略，而 agent 的资源需求以工具调用为单位变化。基于 RQ1（执行模型）、RQ2（资源特征）和 §4.1–§4.2 的差距分析，我们总结 agent 工作负载的三个核心特征及其引出的设计需求：

**特征 1：两层结构——框架基线 + 工具突发。** Agent 维持 ~185MB 的不可压缩框架基线，工具调用叠加持续 1–2 秒、幅度达 15.4× 的内存尖峰。→ **设计需求 R1**：控制逻辑须在内核的内存分配路径上执行，在工具子进程的页面分配请求到达时即时做出准入/限流决策，而非在用户空间轮询后异步调整阈值。

**特征 2：资源需求以工具调用为单位变化。** 不同工具类型的执行时间跨越三个数量级（0.05s–100s），不同语义类别的内存 spike 跨越两个数量级（4.5MB–518MB），且遵循"理解→修改→验证"的阶段性模式。→ **设计需求 R2**：资源控制域须与工具调用边界对齐，支持为每个工具调用（或工具类别）独立设置资源策略，而非在容器粒度设置单一限制。

**特征 3：不可预测性——时间动态性 × 非确定性 × 异构性。** 资源变化率达 3GB/s，同一任务执行时间变异 1.8×，不同类别任务峰值内存差异 20×。→ **设计需求 R3**：资源策略须支持运行时动态调整，基于实时观测（而非历史预测）做出决策，并能适配不同模型和任务类型的资源画像差异。

这三条设计需求——内核路径执行（R1）、工具调用粒度（R2）、运行时自适应（R3）——共同定义了一个现有方案无法覆盖的设计空间。AgentCgroup 正是面向这一空间的系统设计，我们将在下一节详细介绍。
